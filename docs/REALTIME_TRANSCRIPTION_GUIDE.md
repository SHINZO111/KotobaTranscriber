# リアルタイム文字起こし機能 - ユーザーガイド

## 概要

KotobaTranscriberにリアルタイム文字起こし機能が追加されました。この機能により、マイクから直接音声を入力し、リアルタイムで日本語文字起こしを行うことができます。

## 主な特徴

### 🚀 高速処理
- **faster-whisper**を採用し、従来のWhisperと比較して**4～8倍の高速化**
- CPU環境でも実用的なリアルタイム処理が可能
- GPU環境ではさらに高速（float16精度で最適化）

### 🎯 高精度
- kotoba-whisper-v2.2 の日本語特化モデルを使用可能
- 複数のモデルサイズから選択可能（tiny/base/small/medium）
- `base`モデル推奨（精度と速度のバランスが最適）

### 🔊 適応的VAD (Voice Activity Detection)
- 音声検出により無音時の処理をスキップ
- ノイズレベルに応じて自動的に閾値を調整
- 処理効率を大幅に向上

### 💡 ユーザーフレンドリーなUI
- **タブベースのインターフェース**
  - 「ファイル処理」タブ: 従来の機能
  - 「🎤 リアルタイム」タブ: 新機能
- **ハイブリッド表示モード**
  - 確定済みテキスト: 黒色・太字
  - 処理中テキスト: 灰色・イタリック
- **リアルタイムインジケーター**
  - 🎤: 音声検出中
  - 🔇: 無音
- **統計情報表示**
  - 処理チャンク数
  - 平均RTF（Real-Time Factor）
  - 総音声時間

## 使用方法

### 1. アプリケーション起動

```bash
cd F:\VoiceToText\KotobaTranscriber\src
python main.py
```

### 2. リアルタイムタブへ移動

アプリケーションのメインウィンドウで「🎤 リアルタイム」タブをクリックします。

### 3. マイクデバイス設定

1. **マイクデバイス**ドロップダウンから使用するマイクを選択
2. デバイスが表示されない場合は「デバイス更新」ボタンをクリック

### 4. 設定調整（オプション）

#### VAD（音声検出）設定
- **音声検出 (VAD) を有効化**: チェックを入れると無音時の処理をスキップ（推奨）
- **感度スライダー**: 0.005～0.050の範囲で調整
  - 低い値 = 高感度（静かな環境向け）
  - 高い値 = 低感度（ノイズの多い環境向け）
  - デフォルト: 0.010

#### Whisperモデル設定
- **tiny**: 最速だが精度は低い
- **base**: **推奨** - 精度と速度のバランスが最適
- **small**: 高精度だが処理が重い
- **medium**: 最高精度だが非常に重い（GPU推奨）

### 5. 録音開始

「🎤 録音開始」ボタンをクリックします。

- ステータスが「状態: 🎤 録音中...」に変わります
- マイクに向かって話すと、リアルタイムで文字起こし結果が表示されます
- 音声検出インジケーターが🎤（音声あり）と🔇（無音）の間で切り替わります

### 6. 文字起こし確認

- **処理中のテキスト**: 灰色・イタリックで表示（暫定結果）
- **確定済みテキスト**: 黒色・太字で表示（最終結果）

### 7. 録音停止

「⏹ 録音停止」ボタンをクリックします。

- 統計情報が更新されます
  - 処理チャンク数
  - 平均RTF
  - 音声時間

### 8. 結果の保存

1. 「結果を保存」ボタンをクリック
2. ファイル名を入力（デフォルト: リアルタイム文字起こし_YYYYMMDD_HHMMSS.txt）
3. 保存場所を選択

保存されるファイルには以下が含まれます：
- 文字起こし結果の全文
- 統計情報（処理チャンク数、音声時間、処理時間、平均RTF）

### 9. クリア

「クリア」ボタンをクリックすると、表示されているテキストと統計情報がクリアされます。

## 技術仕様

### システム要件

#### 最小要件
- **OS**: Windows 10/11, macOS, Linux
- **CPU**: デュアルコア以上
- **RAM**: 4GB以上
- **Python**: 3.8以上

#### 推奨環境
- **CPU**: クアッドコア以上
- **RAM**: 8GB以上
- **GPU**: CUDA対応GPU（VRAM 2GB以上）
- **Python**: 3.10以上

### 依存ライブラリ

```
faster-whisper>=1.0.0
pyaudio>=0.2.13
PyQt5>=5.15.0
numpy>=1.24.0
torch>=2.0.0
```

### パフォーマンス

#### CPU環境
- **tiny モデル**: RTF ≈ 0.3x（リアルタイム処理可能）
- **base モデル**: RTF ≈ 0.5～1.0x（リアルタイム処理可能）
- **small モデル**: RTF ≈ 1.5～2.0x（遅延あり）

#### GPU環境（CUDA）
- **tiny モデル**: RTF ≈ 0.1x（超高速）
- **base モデル**: RTF ≈ 0.2～0.3x（高速）
- **small モデル**: RTF ≈ 0.4～0.6x（リアルタイム処理可能）
- **medium モデル**: RTF ≈ 0.8～1.2x（リアルタイム処理可能）

※ RTF (Real-Time Factor) = 処理時間 / 音声時間
  - 1.0x以下: リアルタイム処理可能
  - 1.0x以上: 遅延が発生

### 音声処理パラメータ

- **サンプリングレート**: 16000 Hz
- **チャンネル**: モノラル
- **バッファサイズ**: 3秒
- **オーバーラップ**: 50%
- **フォーマット**: int16 → float32 (-1.0～1.0に正規化)

### VADパラメータ

- **閾値**: 0.005～0.050（ユーザー調整可能）
- **最小音声継続時間**: 0.3秒
- **最小無音継続時間**: 1.0秒
- **適応速度**: 0.1（ノイズレベル推定）

## トラブルシューティング

### マイクが認識されない

**症状**: デバイスリストが空、または目的のマイクが表示されない

**解決方法**:
1. マイクがPCに正しく接続されているか確認
2. Windowsの「サウンド設定」でマイクが有効になっているか確認
3. 「デバイス更新」ボタンをクリック
4. アプリケーションを再起動

### 文字起こしが遅い・遅延がある

**症状**: RTFが1.0x以上、または音声と文字起こしにタイムラグがある

**解決方法**:
1. **軽量モデルを使用**: `base` → `tiny`
2. **VADを有効化**: 無音時の処理をスキップ
3. **GPU使用**: CUDA対応GPUがある場合は自動的に使用されます
4. **他のアプリケーションを閉じる**: CPU/メモリリソースを確保

### 音声が検出されない

**症状**: 🎤インジケーターが表示されない、文字起こし結果が出ない

**解決方法**:
1. **マイク音量を確認**: Windowsの「サウンド設定」でマイクレベルを確認
2. **VAD感度を調整**: スライダーを左（高感度）に移動
3. **VADを無効化**: 一時的にVADをオフにして確認
4. **マイクテスト**: Windows「サウンドレコーダー」でマイクが動作するか確認

### 精度が低い

**症状**: 文字起こし結果が不正確

**解決方法**:
1. **高精度モデルを使用**: `base` → `small` or `medium`
2. **マイク距離を調整**: 口とマイクの距離を30cm程度に
3. **ノイズを減らす**: 静かな環境で使用
4. **マイク品質**: 可能であれば高品質なマイクを使用

### メモリエラー

**症状**: 「MemoryError」または「Out of Memory」

**解決方法**:
1. **軽量モデルを使用**: `medium` → `base` or `tiny`
2. **他のアプリケーションを閉じる**: メモリを解放
3. **GPU VRAMを確認**: GPU使用時、VRAMが不足していないか確認

### モデルのダウンロードに失敗

**症状**: 「Model loading failed」

**解決方法**:
1. **インターネット接続を確認**
2. **ファイアウォール設定を確認**: Hugging Faceへのアクセスを許可
3. **手動ダウンロード**: Hugging Faceから手動でモデルをダウンロード
4. **キャッシュをクリア**: `~/.cache/huggingface/` を削除して再試行

## FAQ

### Q1: オフラインで使用できますか？

**A**: はい。初回起動時にモデルがダウンロードされますが、その後はオフラインで使用可能です。

### Q2: 他の言語も文字起こしできますか？

**A**: 現在は日本語に最適化されていますが、faster_whisper_engine.pyの`language`パラメータを変更することで他言語にも対応可能です。

### Q3: 録音データは保存されますか？

**A**: デフォルトでは文字起こし結果のテキストのみ保存されます。音声データを保存したい場合は、RealtimeTranscriberの`save_recording()`メソッドを使用してください。

### Q4: 複数人の会話を文字起こしできますか？

**A**: 現在のバージョンでは話者識別機能はありませんが、将来的に追加予定です。

### Q5: バッチ処理と同時に使用できますか？

**A**: リアルタイム文字起こし中は、ファイル処理を同時に行うことは推奨されません。リソースの競合が発生する可能性があります。

## アーキテクチャ

### コンポーネント構成

```
RealtimeTranscriber (QThread)
├─ RealtimeAudioCapture (音声キャプチャ)
│  ├─ PyAudio (マイク入力)
│  └─ バッファ管理 (deque)
├─ AdaptiveVAD (音声検出)
│  ├─ エネルギー計算
│  └─ 適応的閾値調整
└─ FasterWhisperEngine (文字起こし)
   ├─ WhisperModel (faster-whisper)
   └─ GPU/CPU自動選択
```

### データフロー

```
マイク入力
  ↓
RealtimeAudioCapture (3秒バッファ、50%オーバーラップ)
  ↓
AdaptiveVAD (音声検出)
  ↓ (音声あり)
FasterWhisperEngine (文字起こし)
  ↓
RealtimeTranscriber (結果の蓄積)
  ↓ (PyQt5 Signal)
MainWindow UI (表示)
```

### スレッド構成

- **メインスレッド**: UI更新、ユーザー入力処理
- **RealtimeTranscriberスレッド**: 全体コーディネーション
- **PyAudioコールバックスレッド**: 音声キャプチャ
- **キャプチャループスレッド**: チャンク作成と処理

## 今後の機能追加予定

- [ ] 話者識別機能（Speaker Diarization）
- [ ] タイムスタンプ付き出力
- [ ] リアルタイムテキスト編集
- [ ] カスタムボキャブラリー対応
- [ ] WebSocket経由のストリーミング
- [ ] 録音データの自動保存オプション
- [ ] クラウドモデル対応（API連携）

## ライセンスと著作権

- **faster-whisper**: MIT License
- **PyAudio**: MIT License
- **Whisperモデル**: MIT License (OpenAI)

## 開発者向け情報

### カスタマイズ

#### モデルの変更

`faster_whisper_engine.py`で異なるWhisperモデルを使用できます：

```python
engine = FasterWhisperEngine(
    model_size="large-v2",  # または large-v3
    device="cuda",
    compute_type="float16",
    language="ja"
)
```

#### VADパラメータの調整

`simple_vad.py`でVADの動作を調整できます：

```python
vad = AdaptiveVAD(
    initial_threshold=0.01,
    min_speech_duration=0.3,
    min_silence_duration=1.0,
    adaptation_rate=0.1
)
```

#### バッファサイズの変更

`realtime_audio_capture.py`でバッファサイズを変更できます：

```python
capture = RealtimeAudioCapture(
    sample_rate=16000,
    buffer_duration=5.0  # 3.0 → 5.0秒に変更
)
```

### デバッグモード

ロギングレベルを`DEBUG`に設定すると詳細なログが出力されます：

```python
logging.basicConfig(level=logging.DEBUG)
```

## サポート

問題が解決しない場合は、以下の情報を含めてIssueを作成してください：

- OS とバージョン
- Python バージョン
- インストールされているライブラリのバージョン（`pip list`）
- エラーメッセージの全文
- 実行時のログ

---

**最終更新**: 2025-10-15
**バージョン**: 1.0.0
