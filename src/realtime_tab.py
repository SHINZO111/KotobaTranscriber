"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¿ãƒ–
ãƒã‚¤ã‚¯å…¥åŠ›ã«ã‚ˆã‚‹ãƒ©ã‚¤ãƒ–æ–‡å­—èµ·ã“ã—UI
"""

import logging
import threading
import numpy as np
from typing import Optional, Callable
from PySide6.QtWidgets import (
    QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QTextEdit,
    QLabel, QComboBox, QProgressBar, QCheckBox, QGroupBox,
    QSpinBox, QDoubleSpinBox
)
from PySide6.QtCore import QThread, Signal, Qt, QTimer

logger = logging.getLogger(__name__)

# faster-whisperã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from faster_whisper_engine import FasterWhisperEngine
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    logger.warning("faster-whisper not available")

# PyAudioã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import pyaudio
    import webrtcvad
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False
    logger.warning("pyaudio or webrtcvad not available")


class RealtimeTranscriptionWorker(QThread):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰"""

    # ã‚·ã‚°ãƒŠãƒ«å®šç¾©
    text_ready = Signal(str)  # èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
    partial_ready = Signal(str)  # éƒ¨åˆ†çš„ãªèªè­˜çµæœ
    status_changed = Signal(str)  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´
    error_occurred = Signal(str)  # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ
    volume_changed = Signal(float)  # éŸ³é‡ãƒ¬ãƒ™ãƒ«å¤‰æ›´

    def __init__(self,
                 model_size: str = "base",
                 device: str = "auto",
                 sample_rate: int = 16000,
                 buffer_duration: float = 3.0,
                 vad_threshold: float = 0.5):
        super().__init__()

        self.model_size = model_size
        self.device = device
        self.sample_rate = sample_rate
        self.buffer_duration = buffer_duration
        self.vad_threshold = vad_threshold

        self.engine: Optional[FasterWhisperEngine] = None
        self._running_event = threading.Event()
        self._paused_event = threading.Event()

        # PyAudioé–¢é€£
        self.audio = None
        self.stream = None
        self.vad = None

        # ãƒãƒƒãƒ•ã‚¡ï¼ˆæœ€å¤§60ç§’åˆ†ã§ãƒ¡ãƒ¢ãƒªã‚’åˆ¶é™ï¼‰
        self.audio_buffer = []
        self._buffer_lock = threading.Lock()
        self.buffer_samples = int(sample_rate * buffer_duration)
        self._max_buffer_samples = sample_rate * 60

    def initialize(self) -> bool:
        """ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’åˆæœŸåŒ–"""
        try:
            # faster-whisperã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
            if FASTER_WHISPER_AVAILABLE:
                self.engine = FasterWhisperEngine(
                    model_size=self.model_size,
                    device=self.device,
                    language="ja"
                )
                self.status_changed.emit("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
                if not self.engine.load_model():
                    self.error_occurred.emit("ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False

            # PyAudioåˆæœŸåŒ–
            if PYAUDIO_AVAILABLE:
                self.audio = pyaudio.PyAudio()
                self.vad = webrtcvad.Vad(2)  # æ„Ÿåº¦ãƒ¬ãƒ™ãƒ«2ï¼ˆä¸­ç¨‹åº¦ï¼‰

            return True

        except Exception as e:
            # éƒ¨åˆ†çš„ã«åˆæœŸåŒ–ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if self.engine is not None:
                try:
                    self.engine.unload_model()
                except Exception:
                    pass
                self.engine = None
            if self.audio is not None:
                try:
                    self.audio.terminate()
                except Exception:
                    pass
                self.audio = None
            self.error_occurred.emit(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        if not self.initialize():
            return

        self._running_event.set()
        self.status_changed.emit("éŒ²éŸ³æº–å‚™å®Œäº† - é–‹å§‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")

        # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ é–‹å§‹
        if PYAUDIO_AVAILABLE and self.audio:
            try:
                self.stream = self.audio.open(
                    format=pyaudio.paInt16,
                    channels=1,
                    rate=self.sample_rate,
                    input=True,
                    frames_per_buffer=int(self.sample_rate * 0.03)  # 30ms chunks
                )

                self.status_changed.emit("ğŸ¤ éŒ²éŸ³ä¸­...")

                while self._running_event.is_set():
                    if self._paused_event.is_set():
                        self.msleep(100)
                        continue

                    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒ¼ã‚¿èª­ã¿å–ã‚Š
                    try:
                        data = self.stream.read(
                            int(self.sample_rate * 0.03),
                            exception_on_overflow=False
                        )

                        # NumPyé…åˆ—ã«å¤‰æ›
                        audio_chunk = np.frombuffer(data, dtype=np.int16)
                        audio_float = audio_chunk.astype(np.float32) / 32768.0

                        # éŸ³é‡ãƒ¬ãƒ™ãƒ«è¨ˆç®—
                        volume = np.abs(audio_float).mean()
                        self.volume_changed.emit(float(volume))

                        # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ï¼ˆãƒ¡ãƒ¢ãƒªä¿è­·: æœ€å¤§ã‚µã‚¤ã‚ºã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’ç ´æ£„ï¼‰
                        with self._buffer_lock:
                            self.audio_buffer.extend(audio_float)
                            if len(self.audio_buffer) > self._max_buffer_samples:
                                self.audio_buffer = self.audio_buffer[-self._max_buffer_samples:]

                        # VADãƒã‚§ãƒƒã‚¯
                        is_speech = self._check_vad(data)

                        # ãƒãƒƒãƒ•ã‚¡ãŒæº€ã‚¿ãƒ³ã¾ãŸã¯éŸ³å£°çµ‚äº†æ™‚ã«å‡¦ç†
                        with self._buffer_lock:
                            buf_len = len(self.audio_buffer)
                        if buf_len >= self.buffer_samples or (not is_speech and buf_len > self.sample_rate * 0.5):
                            if buf_len > self.sample_rate * 0.3:  # æœ€ä½0.3ç§’
                                self._process_buffer()
                            else:
                                with self._buffer_lock:
                                    self.audio_buffer = []  # çŸ­ã™ãã‚‹å ´åˆã¯ç ´æ£„

                    except Exception as e:
                        logger.error(f"Audio processing error: {e}", exc_info=True)

            except Exception as e:
                self.error_occurred.emit(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {str(e)}")
            finally:
                # çµ‚äº†å‡¦ç†ï¼ˆä¾‹å¤–æ™‚ã‚‚ãƒªã‚½ãƒ¼ã‚¹ã‚’ç¢ºå®Ÿã«è§£æ”¾ï¼‰
                try:
                    if self.stream:
                        self.stream.stop_stream()
                        self.stream.close()
                except Exception as e:
                    logger.debug(f"Stream cleanup failed: {e}")
                try:
                    if self.audio:
                        self.audio.terminate()
                except Exception as e:
                    logger.debug(f"Audio cleanup failed: {e}")
                # ã‚¨ãƒ³ã‚¸ãƒ³ã®è§£æ”¾
                try:
                    if hasattr(self, 'engine') and self.engine is not None:
                        self.engine.unload_model()
                except Exception as e:
                    logger.debug(f"Engine unload failed: {e}")

        self.status_changed.emit("åœæ­¢ã—ã¾ã—ãŸ")

    def _check_vad(self, data: bytes) -> bool:
        """VADã§éŸ³å£°ã‚’æ¤œå‡º"""
        if not self.vad:
            return True

        try:
            return self.vad.is_speech(data, self.sample_rate)
        except Exception:
            return True

    def _process_buffer(self):
        """ãƒãƒƒãƒ•ã‚¡ã®éŸ³å£°ã‚’å‡¦ç†"""
        if not self.engine:
            return

        with self._buffer_lock:
            if not self.audio_buffer:
                return
            # NumPyé…åˆ—ã«å¤‰æ›ã—ã¦ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
            audio_data = np.array(self.audio_buffer, dtype=np.float32)
            self.audio_buffer = []

        try:
            # æ–‡å­—èµ·ã“ã—
            result = self.engine.transcribe(
                audio_data,
                sample_rate=self.sample_rate,
                beam_size=1,  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨ã«æœ€å°åŒ–
                temperature=0.0
            )

            text = result.get("text", "").strip()

            if text:
                self.text_ready.emit(text)

        except Exception as e:
            logger.error(f"Transcription error: {e}", exc_info=True)

    def stop(self):
        """åœæ­¢"""
        self._running_event.clear()
        self.wait(3000)  # æœ€å¤§3ç§’å¾…æ©Ÿ

    def is_paused(self) -> bool:
        """ä¸€æ™‚åœæ­¢ä¸­ã‹ã©ã†ã‹ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚»ãƒ¼ãƒ•ï¼‰"""
        return self._paused_event.is_set()

    def pause(self):
        """ä¸€æ™‚åœæ­¢"""
        self._paused_event.set()
        self.status_changed.emit("â¸ï¸ ä¸€æ™‚åœæ­¢ä¸­")

    def resume(self):
        """å†é–‹"""
        self._paused_event.clear()
        self.status_changed.emit("ğŸ¤ éŒ²éŸ³ä¸­...")


class RealtimeTab(QWidget):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¿ãƒ–"""

    def __init__(self, parent=None):
        super().__init__(parent)

        self.worker: Optional[RealtimeTranscriptionWorker] = None
        self.is_recording = False

        self.init_ui()

    def init_ui(self):
        """UIåˆæœŸåŒ–"""
        layout = QVBoxLayout(self)
        layout.setContentsMargins(10, 10, 10, 10)
        layout.setSpacing(10)

        # === è¨­å®šã‚°ãƒ«ãƒ¼ãƒ— ===
        settings_group = QGroupBox("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨­å®š")
        settings_layout = QVBoxLayout()

        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_layout = QHBoxLayout()
        model_layout.addWidget(QLabel("ãƒ¢ãƒ‡ãƒ«:"))
        self.model_combo = QComboBox()
        self.model_combo.addItems([
            "tiny (æœ€é€Ÿãƒ»ä½ç²¾åº¦)",
            "base (é€Ÿã„ãƒ»æ™®é€š)",
            "small (æ™®é€šãƒ»è‰¯ç²¾åº¦)",
            "medium (é…ã„ãƒ»é«˜ç²¾åº¦)",
            "large-v3 (æœ€é…ãƒ»æœ€é«˜ç²¾åº¦)"
        ])
        self.model_combo.setCurrentIndex(1)  # baseã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        model_layout.addWidget(self.model_combo)
        model_layout.addStretch()
        settings_layout.addLayout(model_layout)

        # ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
        device_layout = QHBoxLayout()
        device_layout.addWidget(QLabel("ãƒ‡ãƒã‚¤ã‚¹:"))
        self.device_combo = QComboBox()
        self.device_combo.addItems(["è‡ªå‹•", "CPU", "CUDA (GPU)"])
        device_layout.addWidget(self.device_combo)
        device_layout.addStretch()
        settings_layout.addLayout(device_layout)

        # ãƒãƒƒãƒ•ã‚¡æ™‚é–“
        buffer_layout = QHBoxLayout()
        buffer_layout.addWidget(QLabel("ãƒãƒƒãƒ•ã‚¡æ™‚é–“:"))
        self.buffer_spin = QDoubleSpinBox()
        self.buffer_spin.setRange(1.0, 10.0)
        self.buffer_spin.setValue(3.0)
        self.buffer_spin.setSuffix(" ç§’")
        buffer_layout.addWidget(self.buffer_spin)
        buffer_layout.addStretch()
        settings_layout.addLayout(buffer_layout)

        # VADè¨­å®š
        vad_layout = QHBoxLayout()
        self.vad_check = QCheckBox("éŸ³å£°æ¤œå‡º (VAD) ã‚’ä½¿ç”¨")
        self.vad_check.setChecked(True)
        vad_layout.addWidget(self.vad_check)
        settings_layout.addLayout(vad_layout)

        settings_group.setLayout(settings_layout)
        layout.addWidget(settings_group)

        # === éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« ===
        control_layout = QHBoxLayout()

        self.start_button = QPushButton("â–¶ï¸ é–‹å§‹")
        self.start_button.setStyleSheet("font-size: 14px; padding: 10px; background-color: #4CAF50; color: white;")
        self.start_button.clicked.connect(self.toggle_recording)
        control_layout.addWidget(self.start_button)

        self.pause_button = QPushButton("â¸ï¸ ä¸€æ™‚åœæ­¢")
        self.pause_button.setEnabled(False)
        self.pause_button.clicked.connect(self.toggle_pause)
        control_layout.addWidget(self.pause_button)

        self.clear_button = QPushButton("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢")
        self.clear_button.clicked.connect(self.clear_text)
        control_layout.addWidget(self.clear_button)

        layout.addLayout(control_layout)

        # === éŸ³é‡ãƒ¡ãƒ¼ã‚¿ãƒ¼ ===
        volume_layout = QHBoxLayout()
        volume_layout.addWidget(QLabel("éŸ³é‡:"))
        self.volume_bar = QProgressBar()
        self.volume_bar.setRange(0, 100)
        self.volume_bar.setValue(0)
        self.volume_bar.setTextVisible(False)
        volume_layout.addWidget(self.volume_bar)
        layout.addLayout(volume_layout)

        # === ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º ===
        self.status_label = QLabel("æº–å‚™å®Œäº†")
        self.status_label.setStyleSheet("color: #666; font-style: italic;")
        layout.addWidget(self.status_label)

        # === ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢ ===
        self.text_edit = QTextEdit()
        self.text_edit.setPlaceholderText("ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™...")
        self.text_edit.setMinimumHeight(200)
        layout.addWidget(self.text_edit)

        # === ä¿å­˜ãƒœã‚¿ãƒ³ ===
        save_layout = QHBoxLayout()

        self.save_txt_button = QPushButton("ğŸ’¾ TXTä¿å­˜")
        self.save_txt_button.clicked.connect(lambda: self.save_text("txt"))
        save_layout.addWidget(self.save_txt_button)

        self.save_srt_button = QPushButton("ğŸ¬ SRTä¿å­˜")
        self.save_srt_button.clicked.connect(lambda: self.save_text("srt"))
        save_layout.addWidget(self.save_srt_button)

        save_layout.addStretch()
        layout.addLayout(save_layout)

        # åˆ©ç”¨ä¸å¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        missing = []
        if not FASTER_WHISPER_AVAILABLE:
            missing.append("faster-whisper")
        if not PYAUDIO_AVAILABLE:
            missing.append("PyAudio")
        if missing:
            self.status_label.setText(f"âš ï¸ {', '.join(missing)}ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            self.start_button.setEnabled(False)

    def toggle_recording(self):
        """éŒ²éŸ³é–‹å§‹/åœæ­¢"""
        if not self.is_recording:
            self.start_recording()
        else:
            self.stop_recording()

    def start_recording(self):
        """éŒ²éŸ³é–‹å§‹"""
        # è¨­å®šå–å¾—
        model_size = self.model_combo.currentText().split()[0]
        device_map = {"è‡ªå‹•": "auto", "CPU": "cpu", "CUDA (GPU)": "cuda"}
        device = device_map.get(self.device_combo.currentText(), "auto")
        buffer_duration = self.buffer_spin.value()

        # ãƒ¯ãƒ¼ã‚«ãƒ¼ä½œæˆ
        self.worker = RealtimeTranscriptionWorker(
            model_size=model_size,
            device=device,
            buffer_duration=buffer_duration
        )

        # ã‚·ã‚°ãƒŠãƒ«æ¥ç¶š
        self.worker.text_ready.connect(self.on_text_ready)
        self.worker.status_changed.connect(self.on_status_changed)
        self.worker.error_occurred.connect(self.on_error)
        self.worker.volume_changed.connect(self.on_volume_changed)

        # UIæ›´æ–°
        self.start_button.setText("â¹ï¸ åœæ­¢")
        self.start_button.setStyleSheet("font-size: 14px; padding: 10px; background-color: #f44336; color: white;")
        self.pause_button.setEnabled(True)
        self.is_recording = True

        # è¨­å®šç„¡åŠ¹åŒ–
        self.model_combo.setEnabled(False)
        self.device_combo.setEnabled(False)
        self.buffer_spin.setEnabled(False)

        # é–‹å§‹
        self.worker.start()

    def stop_recording(self):
        """éŒ²éŸ³åœæ­¢"""
        if self.worker:
            self.worker.stop()
            self.worker = None

        # UIæ›´æ–°
        self.start_button.setText("â–¶ï¸ é–‹å§‹")
        self.start_button.setStyleSheet("font-size: 14px; padding: 10px; background-color: #4CAF50; color: white;")
        self.pause_button.setEnabled(False)
        self.pause_button.setText("â¸ï¸ ä¸€æ™‚åœæ­¢")
        self.is_recording = False

        # è¨­å®šæœ‰åŠ¹åŒ–
        self.model_combo.setEnabled(True)
        self.device_combo.setEnabled(True)
        self.buffer_spin.setEnabled(True)

        self.status_label.setText("åœæ­¢ã—ã¾ã—ãŸ")
        self.volume_bar.setValue(0)

    def toggle_pause(self):
        """ä¸€æ™‚åœæ­¢/å†é–‹"""
        if not self.worker:
            return

        if self.worker.is_paused():
            self.worker.resume()
            self.pause_button.setText("â¸ï¸ ä¸€æ™‚åœæ­¢")
        else:
            self.worker.pause()
            self.pause_button.setText("â–¶ï¸ å†é–‹")

    def on_text_ready(self, text: str):
        """æ–‡å­—èµ·ã“ã—çµæœã‚’å—ä¿¡"""
        current_text = self.text_edit.toPlainText()
        if current_text:
            self.text_edit.setPlainText(current_text + "\n" + text)
        else:
            self.text_edit.setPlainText(text)

        # è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        scrollbar = self.text_edit.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())

    def on_status_changed(self, status: str):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´ã‚’å—ä¿¡"""
        self.status_label.setText(status)

    def on_error(self, error_msg: str):
        """ã‚¨ãƒ©ãƒ¼ã‚’å—ä¿¡"""
        self.status_label.setText(f"âŒ {error_msg}")
        self.stop_recording()

    def on_volume_changed(self, volume: float):
        """éŸ³é‡å¤‰æ›´ã‚’å—ä¿¡"""
        # éŸ³é‡ã‚’0-100ã®ç¯„å›²ã«å¤‰æ›
        volume_percent = min(100, int(volume * 200))
        self.volume_bar.setValue(volume_percent)

    def clear_text(self):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢"""
        self.text_edit.clear()

    def save_text(self, format_type: str):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜"""
        from PySide6.QtWidgets import QFileDialog
        from datetime import datetime

        text = self.text_edit.toPlainText()
        if not text:
            return

        default_name = f"ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{format_type}"

        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "ä¿å­˜",
            default_name,
            f"{format_type.upper()} Files (*.{format_type})"
        )

        if file_path:
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(text)
                self.status_label.setText(f"âœ… ä¿å­˜ã—ã¾ã—ãŸ: {file_path}")
            except Exception as e:
                self.status_label.setText(f"âŒ ä¿å­˜å¤±æ•—: {str(e)}")


if __name__ == "__main__":
    import sys
    from PySide6.QtWidgets import QApplication

    logging.basicConfig(level=logging.INFO)

    app = QApplication(sys.argv)

    tab = RealtimeTab()
    tab.setWindowTitle("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã— - ãƒ†ã‚¹ãƒˆ")
    tab.resize(500, 600)
    tab.show()

    sys.exit(app.exec())
