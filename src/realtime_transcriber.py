"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼
éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã€VADã€faster-whisperã‚’çµ±åˆ
"""

import logging
import numpy as np
from typing import Optional, Callable, List, Dict, Any
from PyQt5.QtCore import QThread, pyqtSignal
import time

from realtime_audio_capture import RealtimeAudioCapture
from simple_vad import AdaptiveVAD
from faster_whisper_engine import FasterWhisperEngine, FASTER_WHISPER_AVAILABLE

logger = logging.getLogger(__name__)


class RealtimeTranscriber(QThread):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚¹ãƒ¬ãƒƒãƒ‰"""

    # ã‚·ã‚°ãƒŠãƒ«
    transcription_update = pyqtSignal(str, bool)  # (ãƒ†ã‚­ã‚¹ãƒˆ, ç¢ºå®šãƒ•ãƒ©ã‚°)
    status_update = pyqtSignal(str)  # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    error_occurred = pyqtSignal(str)  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    vad_status_changed = pyqtSignal(bool, float)  # (éŸ³å£°æ¤œå‡ºãƒ•ãƒ©ã‚°, ã‚¨ãƒãƒ«ã‚®ãƒ¼)

    def __init__(self,
                 model_size: str = "base",
                 device: str = "auto",
                 device_index: Optional[int] = None,
                 enable_vad: bool = True,
                 vad_threshold: float = 0.01):
        """
        åˆæœŸåŒ–

        Args:
            model_size: Whisperãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º
            device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹
            device_index: ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
            enable_vad: VADæœ‰åŠ¹åŒ–
            vad_threshold: VADé–¾å€¤
        """
        super().__init__()

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.audio_capture = RealtimeAudioCapture(
            device_index=device_index,
            sample_rate=16000,
            buffer_duration=3.0
        )

        self.whisper_engine = FasterWhisperEngine(
            model_size=model_size,
            device=device,
            language="ja"
        )

        self.vad = AdaptiveVAD(
            initial_threshold=vad_threshold,
            min_silence_duration=1.0,
            sample_rate=16000
        ) if enable_vad else None

        # çŠ¶æ…‹ç®¡ç†
        self.is_running = False
        self.is_recording = False
        self.enable_vad = enable_vad

        # æ–‡å­—èµ·ã“ã—çµæœã®è“„ç©
        self.accumulated_text: List[str] = []
        self.pending_text = ""

        # çµ±è¨ˆæƒ…å ±
        self.total_chunks_processed = 0
        self.total_audio_duration = 0.0
        self.total_processing_time = 0.0

        logger.info("RealtimeTranscriber initialized")

    def run(self):
        """ã‚¹ãƒ¬ãƒƒãƒ‰å®Ÿè¡Œ"""
        self.is_running = True

        # Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        self.status_update.emit("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        if not self.whisper_engine.load_model():
            self.error_occurred.emit("Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
            self.is_running = False
            return

        self.status_update.emit("æº–å‚™å®Œäº† - éŒ²éŸ³é–‹å§‹ã—ã¦ãã ã•ã„")
        logger.info("RealtimeTranscriber thread started")

        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
        while self.is_running:
            time.sleep(0.1)  # CPUè² è·è»½æ¸›

        logger.info("RealtimeTranscriber thread stopped")

    def start_recording(self) -> bool:
        """éŒ²éŸ³é–‹å§‹"""
        if self.is_recording:
            logger.warning("Already recording")
            return False

        # VADãƒªã‚»ãƒƒãƒˆ
        if self.vad:
            self.vad.reset()

        # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
        self.audio_capture.on_audio_chunk = self._on_audio_chunk
        if not self.audio_capture.start_capture():
            self.error_occurred.emit("ãƒã‚¤ã‚¯ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False

        self.is_recording = True
        self.accumulated_text = []
        self.pending_text = ""

        self.status_update.emit("ğŸ¤ éŒ²éŸ³ä¸­...")
        logger.info("Recording started")
        return True

    def stop_recording(self) -> bool:
        """éŒ²éŸ³åœæ­¢"""
        if not self.is_recording:
            logger.warning("Not recording")
            return False

        # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£åœæ­¢
        self.audio_capture.stop_capture()
        self.is_recording = False

        # ä¿ç•™ä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºå®š
        if self.pending_text:
            self.accumulated_text.append(self.pending_text)
            self.transcription_update.emit(self.pending_text, True)
            self.pending_text = ""

        self.status_update.emit("éŒ²éŸ³åœæ­¢")
        logger.info("Recording stopped")
        return True

    def _on_audio_chunk(self, audio_chunk: np.ndarray):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            # VADãƒã‚§ãƒƒã‚¯
            if self.vad:
                is_speech, energy = self.vad.is_speech_present(audio_chunk)
                self.vad_status_changed.emit(is_speech, energy)

                if not is_speech:
                    # ç„¡éŸ³æ™‚ã¯å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—
                    return

            # æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            start_time = time.time()
            text = self.whisper_engine.transcribe_stream(audio_chunk, sample_rate=16000)
            processing_time = time.time() - start_time

            if text and text.strip():
                # ç©ºç™½ã®ã¿ã§ãªã„ãƒ†ã‚­ã‚¹ãƒˆ
                text = text.strip()

                # çµ±è¨ˆæ›´æ–°
                self.total_chunks_processed += 1
                self.total_audio_duration += len(audio_chunk) / 16000
                self.total_processing_time += processing_time

                # ä¿ç•™ä¸­ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä¿å­˜ï¼ˆæ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã§ç¢ºå®šï¼‰
                if self.pending_text:
                    # å‰å›ã®ä¿ç•™ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºå®š
                    self.accumulated_text.append(self.pending_text)
                    self.transcription_update.emit(self.pending_text, True)

                self.pending_text = text
                # ä¿ç•™ä¸­ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¡¨ç¤ºï¼ˆç¢ºå®šãƒ•ãƒ©ã‚°=Falseï¼‰
                self.transcription_update.emit(text, False)

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’ãƒ­ã‚°
                rtf = processing_time / (len(audio_chunk) / 16000)
                logger.debug(f"Transcribed: '{text}' (RTF: {rtf:.2f}x)")

        except Exception as e:
            logger.error(f"Error processing audio chunk: {e}")
            self.error_occurred.emit(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

    def get_full_transcription(self) -> str:
        """å…¨æ–‡å­—èµ·ã“ã—çµæœã‚’å–å¾—"""
        all_text = self.accumulated_text.copy()
        if self.pending_text:
            all_text.append(self.pending_text)
        return " ".join(all_text)

    def get_statistics(self) -> Dict[str, Any]:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        avg_rtf = (
            self.total_processing_time / self.total_audio_duration
            if self.total_audio_duration > 0 else 0
        )

        return {
            "chunks_processed": self.total_chunks_processed,
            "audio_duration": self.total_audio_duration,
            "processing_time": self.total_processing_time,
            "average_rtf": avg_rtf,
            "accumulated_lines": len(self.accumulated_text)
        }

    def save_recording(self, filepath: str) -> bool:
        """éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        return self.audio_capture.save_recording(filepath)

    def clear_transcription(self):
        """æ–‡å­—èµ·ã“ã—çµæœã‚’ã‚¯ãƒªã‚¢"""
        self.accumulated_text = []
        self.pending_text = ""
        self.audio_capture.clear_recording()
        logger.info("Transcription cleared")

    def list_devices(self) -> List[Dict]:
        """åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§"""
        return self.audio_capture.list_devices()

    def set_device(self, device_index: int):
        """ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‚’å¤‰æ›´"""
        if self.is_recording:
            logger.warning("Cannot change device while recording")
            return False

        self.audio_capture.device_index = device_index
        logger.info(f"Device changed to index: {device_index}")
        return True

    def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.stop_recording()
        self.is_running = False
        self.audio_capture.cleanup()
        self.whisper_engine.unload_model()
        logger.info("RealtimeTranscriber cleaned up")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨ã‚³ãƒ¼ãƒ‰
    logging.basicConfig(level=logging.INFO)

    from PyQt5.QtWidgets import QApplication
    import sys

    app = QApplication(sys.argv)

    # faster-whisperã®ç¢ºèª
    if not FASTER_WHISPER_AVAILABLE:
        print("ERROR: faster-whisper not available")
        print("Install with: pip install faster-whisper")
        sys.exit(1)

    print("\n=== RealtimeTranscriber Test ===")

    transcriber = RealtimeTranscriber(
        model_size="tiny",  # ãƒ†ã‚¹ãƒˆç”¨ã«è»½é‡ãƒ¢ãƒ‡ãƒ«
        device="auto",
        enable_vad=True
    )

    # ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¡¨ç¤º
    print("\nåˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹:")
    devices = transcriber.list_devices()
    for device in devices:
        print(f"  [{device['index']}] {device['name']}")

    # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
    def on_transcription(text, is_final):
        status = "ç¢ºå®š" if is_final else "å‡¦ç†ä¸­"
        print(f"[{status}] {text}")

    def on_status(status):
        print(f"Status: {status}")

    def on_error(error):
        print(f"ERROR: {error}")

    def on_vad(is_speech, energy):
        if is_speech:
            print(f"ğŸ¤ éŸ³å£°æ¤œå‡º (energy: {energy:.4f})")

    transcriber.transcription_update.connect(on_transcription)
    transcriber.status_update.connect(on_status)
    transcriber.error_occurred.connect(on_error)
    transcriber.vad_status_changed.connect(on_vad)

    # ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
    transcriber.start()

    print("\n5ç§’å¾Œã«éŒ²éŸ³ã‚’é–‹å§‹ã—ã¾ã™...")
    import time
    time.sleep(5)

    print("\néŒ²éŸ³é–‹å§‹ - 10ç§’é–“éŒ²éŸ³ã—ã¾ã™...")
    transcriber.start_recording()
    time.sleep(10)

    print("\néŒ²éŸ³åœæ­¢...")
    transcriber.stop_recording()

    # çµæœè¡¨ç¤º
    print("\n=== æ–‡å­—èµ·ã“ã—çµæœ ===")
    print(transcriber.get_full_transcription())

    # çµ±è¨ˆæƒ…å ±
    stats = transcriber.get_statistics()
    print("\n=== çµ±è¨ˆæƒ…å ± ===")
    print(f"å‡¦ç†ãƒãƒ£ãƒ³ã‚¯æ•°: {stats['chunks_processed']}")
    print(f"éŸ³å£°æ™‚é–“: {stats['audio_duration']:.2f}s")
    print(f"å‡¦ç†æ™‚é–“: {stats['processing_time']:.2f}s")
    print(f"å¹³å‡RTF: {stats['average_rtf']:.2f}x")

    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    transcriber.cleanup()
    transcriber.wait()

    print("\nãƒ†ã‚¹ãƒˆå®Œäº†")
    sys.exit(0)
